{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a93193",
   "metadata": {},
   "source": [
    "# Teradata DBQL Summary Table History Report\n",
    "\n",
    "This notebook demonstrates how to retrieve DBQL summary table history from Teradata PDCR data using the `PDCRInfoReport` class.\n",
    "\n",
    "**Report Parameters:**\n",
    "- User filter: `%` (all users)\n",
    "- Time range: Last 3 years\n",
    "- Data source: `PDCRINFO.DBQLSummaryTbl_Hst`\n",
    "\n",
    "**Focus:**\n",
    "- Top 10 CPU users\n",
    "- CPU usage trends over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff0365",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries for PDCR reporting and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a89b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import the reporting module\n",
    "from src.reports import PDCRInfoReport\n",
    "from src.connection import TeradataConnectionError\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e1eba",
   "metadata": {},
   "source": [
    "## 2. Configure Date Range\n",
    "\n",
    "Calculate the date range for the last 3 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate last 3 years date range\n",
    "end_date = date.today() - timedelta(days=1)  # Yesterday\n",
    "start_date = end_date - timedelta(days=3*365)   # 3 years ago\n",
    "\n",
    "# User filter pattern\n",
    "user_pattern = \"%\"\n",
    "\n",
    "print(f\"Date Range:\")\n",
    "print(f\"  Start Date: {start_date}\")\n",
    "print(f\"  End Date:   {end_date}\")\n",
    "print(f\"  User Pattern: {user_pattern}\")\n",
    "print(f\"  Days: {(end_date - start_date).days + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80286a8",
   "metadata": {},
   "source": [
    "## 3. Initialize PDCR Report Generator\n",
    "\n",
    "Create an instance of the `PDCRInfoReport` class to access PDCR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39067711",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize the report generator\n",
    "    report = PDCRInfoReport()\n",
    "    print(\"✓ PDCRInfoReport initialized successfully\")\n",
    "    \n",
    "    # List available environments\n",
    "    environments = report.conn_mgr.list_environments()\n",
    "    print(f\"✓ Available environments: {environments}\")\n",
    "    \n",
    "except TeradataConnectionError as e:\n",
    "    print(f\"✗ Connection Error: {e}\")\n",
    "    print(\"\\nPlease ensure:\")\n",
    "    print(\"1. td_env.yaml file exists in the project root\")\n",
    "    print(\"2. Copy td_env.yaml.template to td_env.yaml\")\n",
    "    print(\"3. Update credentials for your test/prod environments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43440053",
   "metadata": {},
   "source": [
    "## 4. Retrieve DBQL Summary Table History Data\n",
    "\n",
    "Query `PDCRINFO.DBQLSummaryTbl_Hst` for all users over the last 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Retrieve DBQL summary table history\n",
    "    df = report.get_DBQLSummaryTable_History(\n",
    "        env_name='test',  # Change to 'prod' for production data\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        user_name=user_pattern\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Retrieved {len(df):,} rows from PDCRINFO.DBQLSummaryTbl_Hst\")\n",
    "    print(f\"\\nDataFrame Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error retrieving DBQL summary data: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceebf723",
   "metadata": {},
   "source": [
    "## 5. Display Sample Data\n",
    "\n",
    "Preview the first few rows to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"First 10 rows:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\nColumn Data Types:\")\n",
    "    print(df.dtypes)\n",
    "else:\n",
    "    print(\"No data available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7971142",
   "metadata": {},
   "source": [
    "## 6. Data Summary Statistics\n",
    "\n",
    "Analyze the CPU usage across all retrieved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9796dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DBQL SUMMARY TABLE STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Date range\n",
    "    print(f\"\\nDate Range:\")\n",
    "    print(f\"  First Log Date: {df['LogDate'].min()}\")\n",
    "    print(f\"  Last Log Date:  {df['LogDate'].max()}\")\n",
    "    print(f\"  Unique Dates:   {df['LogDate'].nunique()}\")\n",
    "    \n",
    "    # User coverage\n",
    "    print(f\"\\nUser Coverage:\")\n",
    "    print(f\"  Unique Users:    {df['UserName'].nunique()}\")\n",
    "    print(f\"  Total Queries:   {df['QueryCount'].sum():,.0f}\")\n",
    "    \n",
    "    # CPU usage statistics\n",
    "    print(f\"\\nAMP CPU Time (seconds):\")\n",
    "    print(f\"  Total:   {df['AMPCPUTime'].sum():,.2f}\")\n",
    "    print(f\"  Mean:    {df['AMPCPUTime'].mean():,.2f}\")\n",
    "    print(f\"  Median:  {df['AMPCPUTime'].median():,.2f}\")\n",
    "    print(f\"  Max:     {df['AMPCPUTime'].max():,.2f}\")\n",
    "    \n",
    "    print(f\"\\nParser CPU Time (seconds):\")\n",
    "    print(f\"  Total:   {df['ParserCPUTime'].sum():,.2f}\")\n",
    "    print(f\"  Mean:    {df['ParserCPUTime'].mean():,.2f}\")\n",
    "    print(f\"  Median:  {df['ParserCPUTime'].median():,.2f}\")\n",
    "    print(f\"  Max:     {df['ParserCPUTime'].max():,.2f}\")\n",
    "    \n",
    "    # Total CPU Time\n",
    "    df['TotalCPUTime'] = df['AMPCPUTime'] + df['ParserCPUTime']\n",
    "    print(f\"\\nTotal CPU Time (seconds):\")\n",
    "    print(f\"  Total:   {df['TotalCPUTime'].sum():,.2f}\")\n",
    "    print(f\"  Mean:    {df['TotalCPUTime'].mean():,.2f}\")\n",
    "    print(f\"  Median:  {df['TotalCPUTime'].median():,.2f}\")\n",
    "    print(f\"  Max:     {df['TotalCPUTime'].max():,.2f}\")\n",
    "    \n",
    "    # I/O statistics\n",
    "    print(f\"\\nI/O Statistics:\")\n",
    "    print(f\"  Total I/O Count: {df['TotalIOCount'].sum():,.0f}\")\n",
    "    print(f\"  Total I/O (GB):  {df['TotalIOInKB'].sum() / 1024**2:,.2f}\")\n",
    "else:\n",
    "    print(\"No data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b33efb",
   "metadata": {},
   "source": [
    "## 7. Top 10 CPU Users\n",
    "\n",
    "Identify the top 10 users by total CPU time consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Calculate total CPU time per user\n",
    "    if 'TotalCPUTime' not in df.columns:\n",
    "        df['TotalCPUTime'] = df['AMPCPUTime'] + df['ParserCPUTime']\n",
    "    \n",
    "    # Aggregate by user\n",
    "    user_summary = df.groupby('UserName').agg({\n",
    "        'TotalCPUTime': 'sum',\n",
    "        'AMPCPUTime': 'sum',\n",
    "        'ParserCPUTime': 'sum',\n",
    "        'QueryCount': 'sum',\n",
    "        'TotalIOCount': 'sum',\n",
    "        'TotalIOInKB': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Sort by total CPU time\n",
    "    user_summary = user_summary.sort_values('TotalCPUTime', ascending=False)\n",
    "    \n",
    "    # Convert to hours for readability\n",
    "    user_summary['TotalCPUTime_Hours'] = user_summary['TotalCPUTime'] / 3600\n",
    "    user_summary['AMPCPUTime_Hours'] = user_summary['AMPCPUTime'] / 3600\n",
    "    user_summary['ParserCPUTime_Hours'] = user_summary['ParserCPUTime'] / 3600\n",
    "    user_summary['TotalIOInKB_GB'] = user_summary['TotalIOInKB'] / 1024**2\n",
    "    \n",
    "    print(\"\\nTop 10 Users by Total CPU Time:\")\n",
    "    print(\"=\" * 120)\n",
    "    display(user_summary.head(10)[[\n",
    "        'UserName', 'TotalCPUTime_Hours', 'AMPCPUTime_Hours', 'ParserCPUTime_Hours',\n",
    "        'QueryCount', 'TotalIOInKB_GB'\n",
    "    ]])\n",
    "    \n",
    "    # Calculate percentage of total\n",
    "    total_cpu = user_summary['TotalCPUTime'].sum()\n",
    "    top_10_cpu = user_summary.head(10)['TotalCPUTime'].sum()\n",
    "    print(f\"\\nTop 10 users consume {top_10_cpu/total_cpu*100:.1f}% of total CPU time\")\n",
    "else:\n",
    "    print(\"No data available for user ranking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03807ee9",
   "metadata": {},
   "source": [
    "## 8. Visualize Top 10 CPU Users\n",
    "\n",
    "Bar chart showing the top 10 users by CPU consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358615f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Get top 10 users\n",
    "    top_users = user_summary.head(10)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=top_users,\n",
    "        x='UserName',\n",
    "        y='TotalCPUTime_Hours',\n",
    "        palette='rocket'\n",
    "    )\n",
    "    plt.title('Top 10 Users by Total CPU Time (Hours)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('User Name', fontsize=12)\n",
    "    plt.ylabel('Total CPU Time (Hours)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263747b9",
   "metadata": {},
   "source": [
    "## 9. CPU Usage Per Day Over Period\n",
    "\n",
    "Plot total CPU usage aggregated by day over the entire time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Ensure TotalCPUTime is calculated\n",
    "    if 'TotalCPUTime' not in df.columns:\n",
    "        df['TotalCPUTime'] = df['AMPCPUTime'] + df['ParserCPUTime']\n",
    "    \n",
    "    # Aggregate by LogDate\n",
    "    daily_cpu = df.groupby('LogDate')['TotalCPUTime'].sum().reset_index()\n",
    "    daily_cpu['TotalCPUTime_Hours'] = daily_cpu['TotalCPUTime'] / 3600\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.plot(daily_cpu['LogDate'], daily_cpu['TotalCPUTime_Hours'], \n",
    "             marker='o', linewidth=2, markersize=4, color='#2E86AB')\n",
    "    plt.title('Total CPU Usage Per Day Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Log Date', fontsize=12)\n",
    "    plt.ylabel('Total CPU Time (Hours)', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nDaily CPU Statistics:\")\n",
    "    print(f\"  Average CPU per day: {daily_cpu['TotalCPUTime_Hours'].mean():,.2f} hours\")\n",
    "    print(f\"  Peak CPU day:        {daily_cpu['TotalCPUTime_Hours'].max():,.2f} hours on {daily_cpu.loc[daily_cpu['TotalCPUTime_Hours'].idxmax(), 'LogDate']}\")\n",
    "    print(f\"  Minimum CPU day:     {daily_cpu['TotalCPUTime_Hours'].min():,.2f} hours on {daily_cpu.loc[daily_cpu['TotalCPUTime_Hours'].idxmin(), 'LogDate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678f99b",
   "metadata": {},
   "source": [
    "## 10. CPU Usage Distribution by Top Users\n",
    "\n",
    "Pie chart showing CPU distribution among top users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Get top 10 users and aggregate others\n",
    "    top_n = 10\n",
    "    top_users = user_summary.head(top_n)\n",
    "    other_cpu = user_summary['TotalCPUTime'][top_n:].sum()\n",
    "    \n",
    "    # Create pie data\n",
    "    pie_data = top_users[['UserName', 'TotalCPUTime']].copy()\n",
    "    pie_data = pd.concat([\n",
    "        pie_data,\n",
    "        pd.DataFrame({'UserName': ['Others'], 'TotalCPUTime': [other_cpu]})\n",
    "    ])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(\n",
    "        pie_data['TotalCPUTime'],\n",
    "        labels=pie_data['UserName'],\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=140\n",
    "    )\n",
    "    plt.title('CPU Usage Distribution by User', fontsize=14, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de861dec",
   "metadata": {},
   "source": [
    "## 11. Top Users CPU Trends Over Time\n",
    "\n",
    "Line plot showing CPU usage trends for top 6 users over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fb1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Get top 6 users by total CPU\n",
    "    top_6_users = user_summary.head(6)['UserName'].tolist()\n",
    "    \n",
    "    # Filter data for top users\n",
    "    df_top = df[df['UserName'].isin(top_6_users)].copy()\n",
    "    \n",
    "    if 'TotalCPUTime' not in df_top.columns:\n",
    "        df_top['TotalCPUTime'] = df_top['AMPCPUTime'] + df_top['ParserCPUTime']\n",
    "    \n",
    "    # Aggregate by user and date\n",
    "    user_daily = df_top.groupby(['LogDate', 'UserName'])['TotalCPUTime'].sum().reset_index()\n",
    "    user_daily['TotalCPUTime_Hours'] = user_daily['TotalCPUTime'] / 3600\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for user in top_6_users:\n",
    "        user_data = user_daily[user_daily['UserName'] == user]\n",
    "        plt.plot(user_data['LogDate'], user_data['TotalCPUTime_Hours'], \n",
    "                marker='o', linewidth=2, label=user, alpha=0.7)\n",
    "    \n",
    "    plt.title('CPU Usage Trends for Top 6 Users Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Log Date', fontsize=12)\n",
    "    plt.ylabel('Total CPU Time (Hours)', fontsize=12)\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for trend analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96392364",
   "metadata": {},
   "source": [
    "## 12. Query Count Analysis\n",
    "\n",
    "Analyze query counts by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b568ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Top users by query count\n",
    "    query_summary = df.groupby('UserName')['QueryCount'].sum().reset_index()\n",
    "    query_summary = query_summary.sort_values('QueryCount', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Users by Query Count:\")\n",
    "    print(\"=\" * 80)\n",
    "    display(query_summary.head(20))\n",
    "    \n",
    "    # Plot top 10 by query count\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=query_summary.head(10),\n",
    "        x='UserName',\n",
    "        y='QueryCount',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('Top 10 Users by Query Count', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('User Name', fontsize=12)\n",
    "    plt.ylabel('Query Count', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for query analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3dde30",
   "metadata": {},
   "source": [
    "## 13. Export Results to CSV (Optional)\n",
    "\n",
    "Save the results to CSV files for further analysis or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path('output')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save full data\n",
    "    filename = f\"dbql_summary_{start_date}_{end_date}.csv\"\n",
    "    output_path = output_dir / filename\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Full data exported to: {output_path}\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  File size: {output_path.stat().st_size / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Save user summary\n",
    "    user_summary_path = output_dir / f\"dbql_user_summary_{start_date}_{end_date}.csv\"\n",
    "    user_summary.to_csv(user_summary_path, index=False)\n",
    "    print(f\"\\n✓ User summary exported to: {user_summary_path}\")\n",
    "    \n",
    "    # Save daily CPU data\n",
    "    daily_cpu_path = output_dir / f\"dbql_daily_cpu_{start_date}_{end_date}.csv\"\n",
    "    daily_cpu.to_csv(daily_cpu_path, index=False)\n",
    "    print(f\"✓ Daily CPU data exported to: {daily_cpu_path}\")\n",
    "else:\n",
    "    print(\"No data to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a8c4c",
   "metadata": {},
   "source": [
    "## 14. Close Connections\n",
    "\n",
    "Properly clean up database connections when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f02ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'report' in locals():\n",
    "        report.close()\n",
    "        print(\"✓ All database connections closed successfully\")\n",
    "    else:\n",
    "        print(\"No report instance to close\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error closing connections: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
