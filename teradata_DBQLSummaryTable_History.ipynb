{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532bdb8a",
   "metadata": {},
   "source": [
    "# Teradata DBQL Summary Table History Report\n",
    "\n",
    "This notebook demonstrates how to retrieve and analyze DBQL Summary Table History from Teradata PDCR data using the `PDCRInfoReport` class.\n",
    "\n",
    "**Report Parameters:**\n",
    "- User filter: `%` (all users)\n",
    "- Time range: Last 30 days\n",
    "- Data source: `PDCRINFO.DBQLSummaryTbl_Hst`\n",
    "\n",
    "**Analysis Includes:**\n",
    "- Top CPU consumers\n",
    "- Query performance trends\n",
    "- Daily workload patterns\n",
    "- User activity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66ec12",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries for PDCR reporting and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import the reporting module\n",
    "from src.reports import PDCRInfoReport\n",
    "from src.connection import TeradataConnectionError\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9cc290",
   "metadata": {},
   "source": [
    "## 2. Configure Date Range\n",
    "\n",
    "Calculate the date range for the last 30 days of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate last 30 days date range\n",
    "end_date = date.today() - timedelta(days=1)  # Yesterday\n",
    "start_date = end_date - timedelta(days=30)   # 30 days ago\n",
    "\n",
    "# User filter pattern\n",
    "user_pattern = \"%\"  # All users\n",
    "\n",
    "print(f\"Date Range:\")\n",
    "print(f\"  Start Date: {start_date}\")\n",
    "print(f\"  End Date:   {end_date}\")\n",
    "print(f\"  User Pattern: {user_pattern}\")\n",
    "print(f\"  Days: {(end_date - start_date).days + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a8943",
   "metadata": {},
   "source": [
    "## 3. Initialize PDCR Report Generator\n",
    "\n",
    "Create an instance of the `PDCRInfoReport` class to access PDCR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e09411",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize the report generator\n",
    "    report = PDCRInfoReport()\n",
    "    print(\"✓ PDCRInfoReport initialized successfully\")\n",
    "    \n",
    "    # List available environments\n",
    "    environments = report.conn_mgr.list_environments()\n",
    "    print(f\"✓ Available environments: {environments}\")\n",
    "    \n",
    "except TeradataConnectionError as e:\n",
    "    print(f\"✗ Connection Error: {e}\")\n",
    "    print(\"\\nPlease ensure:\")\n",
    "    print(\"1. td_env.yaml file exists in the project root\")\n",
    "    print(\"2. Copy td_env.yaml.template to td_env.yaml\")\n",
    "    print(\"3. Update credentials for your test/prod environments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a847529",
   "metadata": {},
   "source": [
    "## 4. Retrieve DBQL Summary Table History Data\n",
    "\n",
    "Query `PDCRINFO.DBQLSummaryTbl_Hst` for query performance metrics over the last 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca0df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Retrieve DBQL summary history\n",
    "    df = report.get_DBQLSummaryTable_History(\n",
    "        env_name='test',  # Change to 'prod' for production data\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        user_name=user_pattern\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Retrieved {len(df):,} rows from PDCRINFO.DBQLSummaryTbl_Hst\")\n",
    "    print(f\"\\nDataFrame Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error retrieving DBQL summary data: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68876c2",
   "metadata": {},
   "source": [
    "## 5. Display Sample Data\n",
    "\n",
    "Preview the first few rows to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea9acb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"First 10 rows:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\nColumn Data Types:\")\n",
    "    print(df.dtypes)\n",
    "else:\n",
    "    print(\"No data available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b794aed",
   "metadata": {},
   "source": [
    "## 6. Data Summary Statistics\n",
    "\n",
    "Analyze the query performance metrics across all retrieved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06533f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DBQL SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Date range\n",
    "    print(f\"\\nDate Range:\")\n",
    "    print(f\"  First Log Date: {df['LogDate'].min()}\")\n",
    "    print(f\"  Last Log Date:  {df['LogDate'].max()}\")\n",
    "    print(f\"  Unique Dates:   {df['LogDate'].nunique()}\")\n",
    "    \n",
    "    # User coverage\n",
    "    print(f\"\\nUser Coverage:\")\n",
    "    print(f\"  Unique Users:     {df['UserName'].nunique()}\")\n",
    "    print(f\"  Total Records:    {len(df):,}\")\n",
    "    print(f\"  Total Queries:    {df['QueryCount'].sum():,}\")\n",
    "    \n",
    "    # CPU usage statistics (in seconds, convert to hours)\n",
    "    print(f\"\\nCPU Usage (Hours):\")\n",
    "    print(f\"  Total AMP CPU:      {df['AMPCPUTime'].sum() / 3600:,.2f}\")\n",
    "    print(f\"  Total Parser CPU:   {df['ParserCPUTime'].sum() / 3600:,.2f}\")\n",
    "    print(f\"  Total Combined CPU: {(df['AMPCPUTime'].sum() + df['ParserCPUTime'].sum()) / 3600:,.2f}\")\n",
    "    print(f\"  Avg CPU per Query:  {((df['AMPCPUTime'].sum() + df['ParserCPUTime'].sum()) / df['QueryCount'].sum()):.4f} seconds\")\n",
    "    \n",
    "    # Query execution time\n",
    "    print(f\"\\nQuery Execution Time:\")\n",
    "    print(f\"  Total Query Seconds: {df['QuerySeconds'].sum():,.2f}\")\n",
    "    print(f\"  Avg Query Duration:  {(df['QuerySeconds'].sum() / df['QueryCount'].sum()):.4f} seconds\")\n",
    "    \n",
    "    # I/O statistics\n",
    "    print(f\"\\nI/O Statistics:\")\n",
    "    print(f\"  Total IO Count:     {df['TotalIOCount'].sum():,.0f}\")\n",
    "    print(f\"  Avg IO per Query:   {(df['TotalIOCount'].sum() / df['QueryCount'].sum()):,.0f}\")\n",
    "    if 'TotalIOInKB' in df.columns:\n",
    "        print(f\"  Total IO (GB):      {df['TotalIOInKB'].sum() / 1024**2:,.2f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3e71fc",
   "metadata": {},
   "source": [
    "## 7. Top 10 CPU Users\n",
    "\n",
    "Identify the top 10 users by total CPU time (AMP + Parser)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Calculate total CPU by user\n",
    "    user_cpu = df.groupby('UserName').agg({\n",
    "        'AMPCPUTime': 'sum',\n",
    "        'ParserCPUTime': 'sum',\n",
    "        'QueryCount': 'sum',\n",
    "        'QuerySeconds': 'sum',\n",
    "        'TotalIOCount': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Add total CPU column\n",
    "    user_cpu['TotalCPU'] = user_cpu['AMPCPUTime'] + user_cpu['ParserCPUTime']\n",
    "    user_cpu['TotalCPU_Hours'] = user_cpu['TotalCPU'] / 3600\n",
    "    \n",
    "    # Get top 10\n",
    "    top_10_cpu = user_cpu.nlargest(10, 'TotalCPU')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TOP 10 CPU USERS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    display(top_10_cpu[['UserName', 'QueryCount', 'TotalCPU_Hours', 'QuerySeconds', 'TotalIOCount']].style.format({\n",
    "        'QueryCount': '{:,.0f}',\n",
    "        'TotalCPU_Hours': '{:.2f}',\n",
    "        'QuerySeconds': '{:,.2f}',\n",
    "        'TotalIOCount': '{:,.0f}'\n",
    "    }))\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5861e",
   "metadata": {},
   "source": [
    "## 8. Top 10 Query Count Users\n",
    "\n",
    "Identify the most active users by number of queries executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bbad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Get top 10 by query count\n",
    "    top_10_queries = user_cpu.nlargest(10, 'QueryCount')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TOP 10 MOST ACTIVE USERS (by Query Count)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    display(top_10_queries[['UserName', 'QueryCount', 'TotalCPU_Hours', 'QuerySeconds', 'TotalIOCount']].style.format({\n",
    "        'QueryCount': '{:,.0f}',\n",
    "        'TotalCPU_Hours': '{:.2f}',\n",
    "        'QuerySeconds': '{:,.2f}',\n",
    "        'TotalIOCount': '{:,.0f}'\n",
    "    }))\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd38e6d9",
   "metadata": {},
   "source": [
    "## 9. Visualize Top 10 CPU Users\n",
    "\n",
    "Create a horizontal bar chart showing CPU consumption breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abae391",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Prepare data\n",
    "    top_10_sorted = top_10_cpu.sort_values('TotalCPU_Hours')\n",
    "    \n",
    "    # Create stacked horizontal bars\n",
    "    y_pos = np.arange(len(top_10_sorted))\n",
    "    amp_hours = top_10_sorted['AMPCPUTime'] / 3600\n",
    "    parser_hours = top_10_sorted['ParserCPUTime'] / 3600\n",
    "    \n",
    "    ax.barh(y_pos, amp_hours, label='AMP CPU Time', color='#2E86AB')\n",
    "    ax.barh(y_pos, parser_hours, left=amp_hours, label='Parser CPU Time', color='#A23B72')\n",
    "    \n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(top_10_sorted['UserName'])\n",
    "    ax.set_xlabel('CPU Time (Hours)', fontweight='bold')\n",
    "    ax.set_ylabel('User Name', fontweight='bold')\n",
    "    ax.set_title('Top 10 CPU Users - Last 30 Days', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1ade2",
   "metadata": {},
   "source": [
    "## 10. Daily CPU Usage Trend\n",
    "\n",
    "Plot total CPU usage per day to identify workload patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Aggregate by date\n",
    "    daily_cpu = df.groupby('LogDate').agg({\n",
    "        'AMPCPUTime': 'sum',\n",
    "        'ParserCPUTime': 'sum',\n",
    "        'QueryCount': 'sum',\n",
    "        'TotalIOCount': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_cpu['TotalCPU_Hours'] = (daily_cpu['AMPCPUTime'] + daily_cpu['ParserCPUTime']) / 3600\n",
    "    daily_cpu['AMPCPUTime_Hours'] = daily_cpu['AMPCPUTime'] / 3600\n",
    "    daily_cpu['ParserCPUTime_Hours'] = daily_cpu['ParserCPUTime'] / 3600\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "    \n",
    "    # Plot 1: Stacked area chart\n",
    "    ax1.fill_between(daily_cpu['LogDate'], 0, daily_cpu['AMPCPUTime_Hours'], \n",
    "                     alpha=0.7, label='AMP CPU', color='#2E86AB')\n",
    "    ax1.fill_between(daily_cpu['LogDate'], daily_cpu['AMPCPUTime_Hours'], \n",
    "                     daily_cpu['TotalCPU_Hours'], alpha=0.7, label='Parser CPU', color='#A23B72')\n",
    "    \n",
    "    ax1.set_ylabel('CPU Time (Hours)', fontweight='bold')\n",
    "    ax1.set_title('Daily CPU Usage - Stacked View', fontsize=12, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Line chart with trend\n",
    "    ax2.plot(daily_cpu['LogDate'], daily_cpu['TotalCPU_Hours'], \n",
    "            marker='o', linewidth=2, markersize=5, label='Total CPU', color='#F18F01')\n",
    "    \n",
    "    # Add trend line\n",
    "    if len(daily_cpu) > 1:\n",
    "        x_numeric = np.arange(len(daily_cpu))\n",
    "        z = np.polyfit(x_numeric, daily_cpu['TotalCPU_Hours'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax2.plot(daily_cpu['LogDate'], p(x_numeric), \"--\", alpha=0.7, linewidth=2, \n",
    "                label='Trend', color='#C73E1D')\n",
    "    \n",
    "    ax2.set_xlabel('Date', fontweight='bold')\n",
    "    ax2.set_ylabel('Total CPU Time (Hours)', fontweight='bold')\n",
    "    ax2.set_title('Daily Total CPU Usage with Trend', fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nDaily CPU Statistics:\")\n",
    "    print(f\"  Average: {daily_cpu['TotalCPU_Hours'].mean():.2f} hours\")\n",
    "    print(f\"  Peak:    {daily_cpu['TotalCPU_Hours'].max():.2f} hours on {daily_cpu.loc[daily_cpu['TotalCPU_Hours'].idxmax(), 'LogDate']}\")\n",
    "    print(f\"  Minimum: {daily_cpu['TotalCPU_Hours'].min():.2f} hours on {daily_cpu.loc[daily_cpu['TotalCPU_Hours'].idxmin(), 'LogDate']}\")\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016f078",
   "metadata": {},
   "source": [
    "## 11. Daily Query Count Trend\n",
    "\n",
    "Analyze the number of queries executed per day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    # Bar chart of daily query counts\n",
    "    ax.bar(daily_cpu['LogDate'], daily_cpu['QueryCount'], color='#2E86AB', alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Add average line\n",
    "    avg_queries = daily_cpu['QueryCount'].mean()\n",
    "    ax.axhline(y=avg_queries, color='red', linestyle='--', linewidth=2, \n",
    "               label=f'Average: {avg_queries:,.0f} queries/day')\n",
    "    \n",
    "    ax.set_xlabel('Date', fontweight='bold')\n",
    "    ax.set_ylabel('Query Count', fontweight='bold')\n",
    "    ax.set_title('Daily Query Volume', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Format y-axis with thousands separator\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89e024",
   "metadata": {},
   "source": [
    "## 12. CPU Usage by Day of Week\n",
    "\n",
    "Identify weekly patterns in CPU consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ebf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Add day of week\n",
    "    df_copy = df.copy()\n",
    "    df_copy['DayOfWeek'] = pd.to_datetime(df_copy['LogDate']).dt.day_name()\n",
    "    df_copy['TotalCPU'] = df_copy['AMPCPUTime'] + df_copy['ParserCPUTime']\n",
    "    \n",
    "    # Aggregate by day of week\n",
    "    dow_cpu = df_copy.groupby('DayOfWeek').agg({\n",
    "        'TotalCPU': 'sum',\n",
    "        'QueryCount': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Sort by day of week\n",
    "    day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    dow_cpu['DayOfWeek'] = pd.Categorical(dow_cpu['DayOfWeek'], categories=day_order, ordered=True)\n",
    "    dow_cpu = dow_cpu.sort_values('DayOfWeek')\n",
    "    dow_cpu['TotalCPU_Hours'] = dow_cpu['TotalCPU'] / 3600\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(dow_cpu)))\n",
    "    bars = ax.bar(dow_cpu['DayOfWeek'], dow_cpu['TotalCPU_Hours'], color=colors, edgecolor='black')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.1f}h',\n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Day of Week', fontweight='bold')\n",
    "    ax.set_ylabel('Total CPU Time (Hours)', fontweight='bold')\n",
    "    ax.set_title('CPU Usage by Day of Week', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267745e5",
   "metadata": {},
   "source": [
    "## 13. Top 5 Users - Daily CPU Trends\n",
    "\n",
    "Compare CPU usage trends for the top 5 users over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423b92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Get top 5 users\n",
    "    top_5_users = top_10_cpu.head(5)['UserName'].tolist()\n",
    "    \n",
    "    # Filter and aggregate\n",
    "    df_top5 = df[df['UserName'].isin(top_5_users)].copy()\n",
    "    df_top5['TotalCPU'] = df_top5['AMPCPUTime'] + df_top5['ParserCPUTime']\n",
    "    \n",
    "    user_daily = df_top5.groupby(['LogDate', 'UserName'])['TotalCPU'].sum().reset_index()\n",
    "    user_daily['TotalCPU_Hours'] = user_daily['TotalCPU'] / 3600\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    \n",
    "    for user in top_5_users:\n",
    "        user_data = user_daily[user_daily['UserName'] == user]\n",
    "        ax.plot(user_data['LogDate'], user_data['TotalCPU_Hours'], \n",
    "               marker='o', linewidth=2, markersize=4, label=user)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontweight='bold')\n",
    "    ax.set_ylabel('CPU Time (Hours)', fontweight='bold')\n",
    "    ax.set_title('Top 5 Users - Daily CPU Usage Trends', fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', frameon=True, shadow=True)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5a20d",
   "metadata": {},
   "source": [
    "## 14. Query Performance Heatmap\n",
    "\n",
    "Create a heatmap showing average CPU time per query for top users by day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7932ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Get top 10 users\n",
    "    top_users = top_10_cpu.head(10)['UserName'].tolist()\n",
    "    \n",
    "    # Filter and calculate metrics\n",
    "    df_top = df[df['UserName'].isin(top_users)].copy()\n",
    "    df_top['TotalCPU'] = df_top['AMPCPUTime'] + df_top['ParserCPUTime']\n",
    "    df_top['AvgCPUPerQuery'] = df_top['TotalCPU'] / df_top['QueryCount']\n",
    "    \n",
    "    # Create pivot table\n",
    "    pivot_data = df_top.pivot_table(\n",
    "        values='AvgCPUPerQuery',\n",
    "        index='UserName',\n",
    "        columns='LogDate',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    sns.heatmap(pivot_data, annot=False, fmt='.2f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Avg CPU per Query (seconds)'}, ax=ax)\n",
    "    \n",
    "    ax.set_xlabel('Date', fontweight='bold')\n",
    "    ax.set_ylabel('User Name', fontweight='bold')\n",
    "    ax.set_title('Average CPU Time per Query - Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3e00e4",
   "metadata": {},
   "source": [
    "## 15. I/O vs CPU Scatter Plot\n",
    "\n",
    "Analyze the relationship between I/O operations and CPU time for top users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b342fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Use top 10 user data\n",
    "    for i, user in enumerate(top_10_cpu['UserName'].tolist()):\n",
    "        user_data = top_10_cpu[top_10_cpu['UserName'] == user].iloc[0]\n",
    "        ax.scatter(user_data['TotalIOCount'], user_data['TotalCPU_Hours'], \n",
    "                  s=user_data['QueryCount']/100, alpha=0.6, label=user)\n",
    "    \n",
    "    ax.set_xlabel('Total I/O Count', fontweight='bold')\n",
    "    ax.set_ylabel('Total CPU Time (Hours)', fontweight='bold')\n",
    "    ax.set_title('I/O vs CPU Usage (bubble size = query count)', \n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "    ax.legend(loc='best', frameon=True, shadow=True, ncol=2)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Format axes\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x/1e6)}M'))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bf7a97",
   "metadata": {},
   "source": [
    "## 16. Query Efficiency Analysis\n",
    "\n",
    "Calculate and visualize query efficiency metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed985ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Calculate efficiency metrics for top 10 users\n",
    "    efficiency = top_10_cpu.copy()\n",
    "    efficiency['AvgCPUPerQuery'] = efficiency['TotalCPU'] / efficiency['QueryCount']\n",
    "    efficiency['AvgIOPerQuery'] = efficiency['TotalIOCount'] / efficiency['QueryCount']\n",
    "    efficiency['AvgDurationPerQuery'] = efficiency['QuerySeconds'] / efficiency['QueryCount']\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"QUERY EFFICIENCY METRICS - TOP 10 CPU USERS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    display(efficiency[['UserName', 'QueryCount', 'AvgCPUPerQuery', \n",
    "                        'AvgDurationPerQuery', 'AvgIOPerQuery']].style.format({\n",
    "        'QueryCount': '{:,.0f}',\n",
    "        'AvgCPUPerQuery': '{:.4f}',\n",
    "        'AvgDurationPerQuery': '{:.4f}',\n",
    "        'AvgIOPerQuery': '{:,.0f}'\n",
    "    }))\n",
    "    \n",
    "    # Visualize efficiency\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Average CPU per query\n",
    "    efficiency_sorted = efficiency.sort_values('AvgCPUPerQuery', ascending=True)\n",
    "    ax1.barh(efficiency_sorted['UserName'], efficiency_sorted['AvgCPUPerQuery'], \n",
    "            color='#2E86AB', edgecolor='black')\n",
    "    ax1.set_xlabel('Avg CPU per Query (seconds)', fontweight='bold')\n",
    "    ax1.set_ylabel('User Name', fontweight='bold')\n",
    "    ax1.set_title('Average CPU Time per Query', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Average Duration per query\n",
    "    duration_sorted = efficiency.sort_values('AvgDurationPerQuery', ascending=True)\n",
    "    ax2.barh(duration_sorted['UserName'], duration_sorted['AvgDurationPerQuery'], \n",
    "            color='#A23B72', edgecolor='black')\n",
    "    ax2.set_xlabel('Avg Duration per Query (seconds)', fontweight='bold')\n",
    "    ax2.set_ylabel('User Name', fontweight='bold')\n",
    "    ax2.set_title('Average Query Duration', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8cc106",
   "metadata": {},
   "source": [
    "## 17. Export Results to CSV\n",
    "\n",
    "Save the results to CSV files for further analysis or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7041b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path('output')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Export full dataset\n",
    "    filename = f\"dbql_summary_history_{start_date}_{end_date}.csv\"\n",
    "    output_path = output_dir / filename\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Full dataset exported to: {output_path}\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  File size: {output_path.stat().st_size / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Export top 10 CPU users\n",
    "    summary_file = f\"dbql_top10_cpu_users_{start_date}_{end_date}.csv\"\n",
    "    summary_path = output_dir / summary_file\n",
    "    top_10_cpu.to_csv(summary_path, index=False)\n",
    "    print(f\"\\n✓ Top 10 CPU users exported to: {summary_path}\")\n",
    "    \n",
    "    # Export daily summary\n",
    "    daily_file = f\"dbql_daily_summary_{start_date}_{end_date}.csv\"\n",
    "    daily_path = output_dir / daily_file\n",
    "    daily_cpu.to_csv(daily_path, index=False)\n",
    "    print(f\"\\n✓ Daily summary exported to: {daily_path}\")\n",
    "else:\n",
    "    print(\"No data to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526dc0c",
   "metadata": {},
   "source": [
    "## 18. Close Connections\n",
    "\n",
    "Properly clean up database connections when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc78a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all connections\n",
    "report.close()\n",
    "print(\"✓ Database connections closed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb0bd63",
   "metadata": {},
   "source": [
    "# Teradata DBQL Summary Table History Report\n",
    "\n",
    "This notebook demonstrates how to retrieve and analyze DBQL Summary Table History from Teradata PDCR data using the `PDCRInfoReport` class.\n",
    "\n",
    "**Report Parameters:**\n",
    "- User filter: `%` (all users)\n",
    "- Time range: Last 30 days\n",
    "- Data source: `PDCRINFO.DBQLSummaryTbl_Hst`\n",
    "\n",
    "**Analysis Includes:**\n",
    "- Top 10 CPU users\n",
    "- CPU usage trends over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7da035",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries for PDCR reporting and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c6ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import the reporting module\n",
    "from src.reports import PDCRInfoReport\n",
    "from src.connection import TeradataConnectionError\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1822d15",
   "metadata": {},
   "source": [
    "## 2. Configure Date Range\n",
    "\n",
    "Calculate the date range for the last 30 days of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate date range - last 30 days\n",
    "end_date = date.today() - timedelta(days=1)  # Yesterday\n",
    "start_date = end_date - timedelta(days=30)  # 30 days ago\n",
    "\n",
    "# User filter\n",
    "user_name = '%'  # All users\n",
    "\n",
    "print(\"Date Range:\")\n",
    "print(f\"  Start Date: {start_date}\")\n",
    "print(f\"  End Date:   {end_date}\")\n",
    "print(f\"  User Pattern: {user_name}\")\n",
    "print(f\"  Days: {(end_date - start_date).days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd188cb8",
   "metadata": {},
   "source": [
    "## 3. Initialize Report Generator\n",
    "\n",
    "Create an instance of PDCRInfoReport using the default configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62173e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the report generator\n",
    "report = PDCRInfoReport()\n",
    "print(\"✓ PDCRInfoReport initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61045ccf",
   "metadata": {},
   "source": [
    "## 4. Fetch DBQL Summary Data\n",
    "\n",
    "Retrieve DBQL Summary Table History data from the Teradata environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afcdd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the DBQL summary data\n",
    "try:\n",
    "    df = report.get_DBQLSummaryTable_History(\n",
    "        env_name='prod',\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        user_name=user_name\n",
    "    )\n",
    "    print(f\"✓ Successfully retrieved {len(df):,} records\")\n",
    "    print(f\"\\nDate range in data: {df['LogDate'].min()} to {df['LogDate'].max()}\")\n",
    "    print(f\"Unique users: {df['UserName'].nunique():,}\")\n",
    "    print(f\"Total queries: {df['QueryCount'].sum():,}\")\n",
    "except TeradataConnectionError as e:\n",
    "    print(f\"✗ Failed to retrieve data: {e}\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0109216e",
   "metadata": {},
   "source": [
    "## 5. Data Overview\n",
    "\n",
    "Display basic statistics and structure of the retrieved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5309401",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"Data Shape:\", df.shape)\n",
    "    print(\"\\nColumn Names:\")\n",
    "    print(df.columns.tolist())\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    display(df.head())\n",
    "    print(\"\\nData Types:\")\n",
    "    print(df.dtypes)\n",
    "else:\n",
    "    print(\"No data available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ad012",
   "metadata": {},
   "source": [
    "## 6. Top 10 CPU Users - By Total AMP CPU Time\n",
    "\n",
    "Identify the top 10 users by total AMP CPU time over the reporting period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab8c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Aggregate CPU time by user\n",
    "    top_cpu_users = df.groupby('UserName').agg({\n",
    "        'AMPCPUTime': 'sum',\n",
    "        'ParserCPUTime': 'sum',\n",
    "        'QueryCount': 'sum',\n",
    "        'QuerySeconds': 'sum',\n",
    "        'TotalIOCount': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate total CPU time\n",
    "    top_cpu_users['TotalCPUTime'] = top_cpu_users['AMPCPUTime'] + top_cpu_users['ParserCPUTime']\n",
    "    \n",
    "    # Sort by total CPU time and get top 10\n",
    "    top_cpu_users = top_cpu_users.sort_values('TotalCPUTime', ascending=False).head(10)\n",
    "    \n",
    "    # Convert CPU time to hours for readability\n",
    "    top_cpu_users['AMPCPUTime_Hours'] = top_cpu_users['AMPCPUTime'] / 3600\n",
    "    top_cpu_users['ParserCPUTime_Hours'] = top_cpu_users['ParserCPUTime'] / 3600\n",
    "    top_cpu_users['TotalCPUTime_Hours'] = top_cpu_users['TotalCPUTime'] / 3600\n",
    "    \n",
    "    print(\"\\n=== TOP 10 CPU USERS ===\")\n",
    "    print(\"\\nSorted by Total CPU Time (AMP + Parser)\\n\")\n",
    "    \n",
    "    display(top_cpu_users[[\n",
    "        'UserName', 'QueryCount', 'TotalCPUTime_Hours', \n",
    "        'AMPCPUTime_Hours', 'ParserCPUTime_Hours', 'TotalIOCount'\n",
    "    ]].style.format({\n",
    "        'QueryCount': '{:,.0f}',\n",
    "        'TotalCPUTime_Hours': '{:.2f}',\n",
    "        'AMPCPUTime_Hours': '{:.2f}',\n",
    "        'ParserCPUTime_Hours': '{:.2f}',\n",
    "        'TotalIOCount': '{:,.0f}'\n",
    "    }))\n",
    "else:\n",
    "    print(\"No data available for CPU user analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7418a25",
   "metadata": {},
   "source": [
    "## 7. Visualize Top 10 CPU Users - Bar Chart\n",
    "\n",
    "Create a bar chart showing the top 10 CPU users with AMP and Parser CPU breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f83d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    x = np.arange(len(top_cpu_users))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Create bars\n",
    "    bars1 = ax.bar(x - width/2, top_cpu_users['AMPCPUTime_Hours'], width, \n",
    "                   label='AMP CPU Time', color='#2E86AB')\n",
    "    bars2 = ax.bar(x + width/2, top_cpu_users['ParserCPUTime_Hours'], width,\n",
    "                   label='Parser CPU Time', color='#A23B72')\n",
    "    \n",
    "    # Customize chart\n",
    "    ax.set_xlabel('User Name', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('CPU Time (Hours)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Top 10 CPU Users - AMP vs Parser CPU Time', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(top_cpu_users['UserName'], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34075c80",
   "metadata": {},
   "source": [
    "## 8. CPU Usage Per Day - Overall System\n",
    "\n",
    "Plot total CPU usage per day across all users to identify trends and patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Aggregate CPU time by date\n",
    "    daily_cpu = df.groupby('LogDate').agg({\n",
    "        'AMPCPUTime': 'sum',\n",
    "        'ParserCPUTime': 'sum',\n",
    "        'QueryCount': 'sum',\n",
    "        'TotalIOCount': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate total CPU time in hours\n",
    "    daily_cpu['TotalCPUTime_Hours'] = (daily_cpu['AMPCPUTime'] + daily_cpu['ParserCPUTime']) / 3600\n",
    "    daily_cpu['AMPCPUTime_Hours'] = daily_cpu['AMPCPUTime'] / 3600\n",
    "    daily_cpu['ParserCPUTime_Hours'] = daily_cpu['ParserCPUTime'] / 3600\n",
    "    \n",
    "    # Sort by date\n",
    "    daily_cpu = daily_cpu.sort_values('LogDate')\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))\n",
    "    \n",
    "    # Plot 1: Stacked area chart of CPU usage\n",
    "    ax1.fill_between(daily_cpu['LogDate'], 0, daily_cpu['AMPCPUTime_Hours'], \n",
    "                     alpha=0.7, label='AMP CPU Time', color='#2E86AB')\n",
    "    ax1.fill_between(daily_cpu['LogDate'], daily_cpu['AMPCPUTime_Hours'], \n",
    "                     daily_cpu['TotalCPUTime_Hours'],\n",
    "                     alpha=0.7, label='Parser CPU Time', color='#A23B72')\n",
    "    \n",
    "    ax1.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('CPU Time (Hours)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Daily CPU Usage - Stacked View', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Line chart with trend\n",
    "    ax2.plot(daily_cpu['LogDate'], daily_cpu['TotalCPUTime_Hours'], \n",
    "            marker='o', linewidth=2, label='Total CPU Time', color='#F18F01')\n",
    "    \n",
    "    # Add trend line\n",
    "    if len(daily_cpu) > 1:\n",
    "        x_numeric = np.arange(len(daily_cpu))\n",
    "        z = np.polyfit(x_numeric, daily_cpu['TotalCPUTime_Hours'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax2.plot(daily_cpu['LogDate'], p(x_numeric), \"r--\", \n",
    "                alpha=0.8, linewidth=2, label='Trend')\n",
    "    \n",
    "    ax2.set_xlabel('Date', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Total CPU Time (Hours)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Daily Total CPU Usage with Trend', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"\\n=== DAILY CPU USAGE STATISTICS ===\")\n",
    "    print(f\"Average daily CPU time: {daily_cpu['TotalCPUTime_Hours'].mean():.2f} hours\")\n",
    "    print(f\"Peak daily CPU time: {daily_cpu['TotalCPUTime_Hours'].max():.2f} hours on {daily_cpu.loc[daily_cpu['TotalCPUTime_Hours'].idxmax(), 'LogDate']}\")\n",
    "    print(f\"Minimum daily CPU time: {daily_cpu['TotalCPUTime_Hours'].min():.2f} hours on {daily_cpu.loc[daily_cpu['TotalCPUTime_Hours'].idxmin(), 'LogDate']}\")\n",
    "    print(f\"Total CPU time over period: {daily_cpu['TotalCPUTime_Hours'].sum():.2f} hours\")\n",
    "else:\n",
    "    print(\"No data available for daily CPU visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e47fd3",
   "metadata": {},
   "source": [
    "## 9. CPU Usage Per Day - Top 10 Users\n",
    "\n",
    "Plot CPU usage trends over time for each of the top 10 users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0689ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Get top 10 user names from previous analysis\n",
    "    top_10_users = top_cpu_users['UserName'].tolist()\n",
    "    \n",
    "    # Filter data for top 10 users\n",
    "    df_top_users = df[df['UserName'].isin(top_10_users)].copy()\n",
    "    \n",
    "    # Aggregate by date and user\n",
    "    user_daily_cpu = df_top_users.groupby(['LogDate', 'UserName']).agg({\n",
    "        'AMPCPUTime': 'sum',\n",
    "        'ParserCPUTime': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate total CPU time in hours\n",
    "    user_daily_cpu['TotalCPUTime_Hours'] = (user_daily_cpu['AMPCPUTime'] + user_daily_cpu['ParserCPUTime']) / 3600\n",
    "    \n",
    "    # Create subplots for top users\n",
    "    fig, axes = plt.subplots(5, 2, figsize=(16, 20))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, user in enumerate(top_10_users):\n",
    "        ax = axes[i]\n",
    "        user_data = user_daily_cpu[user_daily_cpu['UserName'] == user].sort_values('LogDate')\n",
    "        \n",
    "        if not user_data.empty:\n",
    "            # Plot CPU usage\n",
    "            ax.plot(user_data['LogDate'], user_data['TotalCPUTime_Hours'], \n",
    "                   marker='o', linewidth=2, label='CPU Time', color='#2E86AB')\n",
    "            \n",
    "            # Add trend line if enough data points\n",
    "            if len(user_data) > 1:\n",
    "                x_numeric = np.arange(len(user_data))\n",
    "                z = np.polyfit(x_numeric, user_data['TotalCPUTime_Hours'], 1)\n",
    "                p = np.poly1d(z)\n",
    "                ax.plot(user_data['LogDate'], p(x_numeric), \"r--\", \n",
    "                       alpha=0.7, linewidth=2, label='Trend')\n",
    "            \n",
    "            ax.set_title(f'{user}', fontsize=11, fontweight='bold')\n",
    "            ax.set_xlabel('Date', fontsize=9)\n",
    "            ax.set_ylabel('CPU Time (Hours)', fontsize=9)\n",
    "            ax.grid(alpha=0.3)\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "            ax.tick_params(axis='y', labelsize=8)\n",
    "    \n",
    "    plt.suptitle('Daily CPU Usage - Top 10 Users', fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for user-level CPU visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ff822f",
   "metadata": {},
   "source": [
    "## 10. Query Performance Metrics\n",
    "\n",
    "Analyze average query performance metrics for top users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Calculate average metrics per query for top users\n",
    "    top_10_users = top_cpu_users['UserName'].tolist()\n",
    "    df_top = df[df['UserName'].isin(top_10_users)].copy()\n",
    "    \n",
    "    performance_metrics = df_top.groupby('UserName').agg({\n",
    "        'QueryCount': 'sum',\n",
    "        'AMPCPUTime': 'sum',\n",
    "        'ParserCPUTime': 'sum',\n",
    "        'QuerySeconds': 'sum',\n",
    "        'TotalIOCount': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculate averages per query\n",
    "    performance_metrics['AvgCPUTimePerQuery'] = (performance_metrics['AMPCPUTime'] + performance_metrics['ParserCPUTime']) / performance_metrics['QueryCount']\n",
    "    performance_metrics['AvgElapsedTimePerQuery'] = performance_metrics['QuerySeconds'] / performance_metrics['QueryCount']\n",
    "    performance_metrics['AvgIOPerQuery'] = performance_metrics['TotalIOCount'] / performance_metrics['QueryCount']\n",
    "    \n",
    "    # Sort by average CPU time\n",
    "    performance_metrics = performance_metrics.sort_values('AvgCPUTimePerQuery', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== QUERY PERFORMANCE METRICS - TOP 10 USERS ===\")\n",
    "    print(\"\\nAverage resource consumption per query\\n\")\n",
    "    \n",
    "    display(performance_metrics[[\n",
    "        'UserName', 'QueryCount', 'AvgCPUTimePerQuery', \n",
    "        'AvgElapsedTimePerQuery', 'AvgIOPerQuery'\n",
    "    ]].style.format({\n",
    "        'QueryCount': '{:,.0f}',\n",
    "        'AvgCPUTimePerQuery': '{:.4f}',\n",
    "        'AvgElapsedTimePerQuery': '{:.4f}',\n",
    "        'AvgIOPerQuery': '{:,.0f}'\n",
    "    }))\n",
    "else:\n",
    "    print(\"No data available for performance analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f53af",
   "metadata": {},
   "source": [
    "## 11. Export Results to CSV (Optional)\n",
    "\n",
    "Save the results to CSV files for further analysis or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9c731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path('output')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Generate filename with date range\n",
    "    filename = f\"dbql_summary_history_{start_date}_{end_date}.csv\"\n",
    "    output_path = output_dir / filename\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Data exported to: {output_path}\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  File size: {output_path.stat().st_size / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Also export top 10 CPU users summary\n",
    "    summary_filename = f\"dbql_top10_cpu_users_{start_date}_{end_date}.csv\"\n",
    "    summary_path = output_dir / summary_filename\n",
    "    top_cpu_users.to_csv(summary_path, index=False)\n",
    "    print(f\"\\n✓ Top 10 CPU users exported to: {summary_path}\")\n",
    "else:\n",
    "    print(\"No data to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0fed89",
   "metadata": {},
   "source": [
    "## 12. Close Connections\n",
    "\n",
    "Properly clean up database connections when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c50f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all connections\n",
    "report.close()\n",
    "print(\"✓ Database connections closed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a93193",
   "metadata": {},
   "source": [
    "# Teradata DBQL Summary Table History Report\n",
    "\n",
    "This notebook demonstrates how to retrieve DBQL summary table history from Teradata PDCR data using the `PDCRInfoReport` class.\n",
    "\n",
    "**Report Parameters:**\n",
    "- User filter: `%` (all users)\n",
    "- Time range: Last 3 years\n",
    "- Data source: `PDCRINFO.DBQLSummaryTbl_Hst`\n",
    "\n",
    "**Focus:**\n",
    "- Top 10 CPU users\n",
    "- CPU usage trends over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff0365",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries for PDCR reporting and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a89b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import the reporting module\n",
    "from src.reports import PDCRInfoReport\n",
    "try:\n",
    "    from src.reports import PDCRInfoReport\n",
    "    from src.connection import TeradataConnectionError\n",
    "except SyntaxError as e:\n",
    "    print(f\"✗ Syntax Error in reports.py: {e}\")\n",
    "    print(f\"  File: {e.filename}\")\n",
    "    print(f\"  Line: {e.lineno}\")\n",
    "    print(f\"  Text: {e.text}\")\n",
    "    raise\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e1eba",
   "metadata": {},
   "source": [
    "## 2. Configure Date Range\n",
    "\n",
    "Calculate the date range for the last 3 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4cf0c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Range:\n",
      "  Start Date: 2023-01-15\n",
      "  End Date:   2026-01-14\n",
      "  User Pattern: %\n",
      "  Days: 1096\n"
     ]
    }
   ],
   "source": [
    "# Calculate last 3 years date range\n",
    "end_date = date.today() - timedelta(days=1)  # Yesterday\n",
    "start_date = end_date - timedelta(days=3*365)   # 3 years ago\n",
    "\n",
    "# User filter pattern\n",
    "user_pattern = \"%\"\n",
    "\n",
    "print(f\"Date Range:\")\n",
    "print(f\"  Start Date: {start_date}\")\n",
    "print(f\"  End Date:   {end_date}\")\n",
    "print(f\"  User Pattern: {user_pattern}\")\n",
    "print(f\"  Days: {(end_date - start_date).days + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80286a8",
   "metadata": {},
   "source": [
    "## 3. Initialize PDCR Report Generator\n",
    "\n",
    "Create an instance of the `PDCRInfoReport` class to access PDCR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39067711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 21:41:23,023 - src.connection - INFO - Loaded configuration for: ['test', 'prod']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PDCRInfoReport initialized successfully\n",
      "✓ Available environments: ['test', 'prod']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Initialize the report generator\n",
    "    report = PDCRInfoReport()\n",
    "    print(\"✓ PDCRInfoReport initialized successfully\")\n",
    "    \n",
    "    # List available environments\n",
    "    environments = report.conn_mgr.list_environments()\n",
    "    print(f\"✓ Available environments: {environments}\")\n",
    "    \n",
    "except TeradataConnectionError as e:\n",
    "    print(f\"✗ Connection Error: {e}\")\n",
    "    print(\"\\nPlease ensure:\")\n",
    "    print(\"1. td_env.yaml file exists in the project root\")\n",
    "    print(\"2. Copy td_env.yaml.template to td_env.yaml\")\n",
    "    print(\"3. Update credentials for your test/prod environments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43440053",
   "metadata": {},
   "source": [
    "## 4. Retrieve DBQL Summary Table History Data\n",
    "\n",
    "Query `PDCRINFO.DBQLSummaryTbl_Hst` for all users over the last 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce01a42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ Error retrieving DBQL summary data: 'PDCRInfoReport' object has no attribute 'get_DBQLSummaryTable_History'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Retrieve DBQL summary table history\n",
    "    df = report.get_DBQLSummaryTable_History(\n",
    "        env_name='test',  # Change to 'prod' for production data\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        user_name=user_pattern\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Retrieved {len(df):,} rows from PDCRINFO.DBQLSummaryTbl_Hst\")\n",
    "    print(f\"\\nDataFrame Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error retrieving DBQL summary data: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceebf723",
   "metadata": {},
   "source": [
    "## 5. Display Sample Data\n",
    "\n",
    "Preview the first few rows to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c521af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data available to display.\n"
     ]
    }
   ],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"First 10 rows:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\nColumn Data Types:\")\n",
    "    print(df.dtypes)\n",
    "else:\n",
    "    print(\"No data available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7971142",
   "metadata": {},
   "source": [
    "## 6. Data Summary Statistics\n",
    "\n",
    "Analyze the CPU usage across all retrieved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9796dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DBQL SUMMARY TABLE STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Date range\n",
    "    print(f\"\\nDate Range:\")\n",
    "    print(f\"  First Log Date: {df['LogDate'].min()}\")\n",
    "    print(f\"  Last Log Date:  {df['LogDate'].max()}\")\n",
    "    print(f\"  Unique Dates:   {df['LogDate'].nunique()}\")\n",
    "    \n",
    "    # User coverage\n",
    "    print(f\"\\nUser Coverage:\")\n",
    "    print(f\"  Unique Users:    {df['UserName'].nunique()}\")\n",
    "    print(f\"  Total Queries:   {df['QueryCount'].sum():,.0f}\")\n",
    "    \n",
    "    # CPU usage statistics\n",
    "    print(f\"\\nAMP CPU Time (seconds):\")\n",
    "    print(f\"  Total:   {df['AMPCPUTime'].sum():,.2f}\")\n",
    "    print(f\"  Mean:    {df['AMPCPUTime'].mean():,.2f}\")\n",
    "    print(f\"  Median:  {df['AMPCPUTime'].median():,.2f}\")\n",
    "    print(f\"  Max:     {df['AMPCPUTime'].max():,.2f}\")\n",
    "    \n",
    "    print(f\"\\nParser CPU Time (seconds):\")\n",
    "    print(f\"  Total:   {df['ParserCPUTime'].sum():,.2f}\")\n",
    "    print(f\"  Mean:    {df['ParserCPUTime'].mean():,.2f}\")\n",
    "    print(f\"  Median:  {df['ParserCPUTime'].median():,.2f}\")\n",
    "    print(f\"  Max:     {df['ParserCPUTime'].max():,.2f}\")\n",
    "    \n",
    "    # Total CPU Time\n",
    "    df['TotalCPUTime'] = df['AMPCPUTime'] + df['ParserCPUTime']\n",
    "    print(f\"\\nTotal CPU Time (seconds):\")\n",
    "    print(f\"  Total:   {df['TotalCPUTime'].sum():,.2f}\")\n",
    "    print(f\"  Mean:    {df['TotalCPUTime'].mean():,.2f}\")\n",
    "    print(f\"  Median:  {df['TotalCPUTime'].median():,.2f}\")\n",
    "    print(f\"  Max:     {df['TotalCPUTime'].max():,.2f}\")\n",
    "    \n",
    "    # I/O statistics\n",
    "    print(f\"\\nI/O Statistics:\")\n",
    "    print(f\"  Total I/O Count: {df['TotalIOCount'].sum():,.0f}\")\n",
    "    print(f\"  Total I/O (GB):  {df['TotalIOInKB'].sum() / 1024**2:,.2f}\")\n",
    "else:\n",
    "    print(\"No data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b33efb",
   "metadata": {},
   "source": [
    "## 7. Top 10 CPU Users\n",
    "\n",
    "Identify the top 10 users by total CPU time consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Calculate total CPU time per user\n",
    "    if 'TotalCPUTime' not in df.columns:\n",
    "        df['TotalCPUTime'] = df['AMPCPUTime'] + df['ParserCPUTime']\n",
    "    \n",
    "    # Aggregate by user\n",
    "    user_summary = df.groupby('UserName').agg({\n",
    "        'TotalCPUTime': 'sum',\n",
    "        'AMPCPUTime': 'sum',\n",
    "        'ParserCPUTime': 'sum',\n",
    "        'QueryCount': 'sum',\n",
    "        'TotalIOCount': 'sum',\n",
    "        'TotalIOInKB': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Sort by total CPU time\n",
    "    user_summary = user_summary.sort_values('TotalCPUTime', ascending=False)\n",
    "    \n",
    "    # Convert to hours for readability\n",
    "    user_summary['TotalCPUTime_Hours'] = user_summary['TotalCPUTime'] / 3600\n",
    "    user_summary['AMPCPUTime_Hours'] = user_summary['AMPCPUTime'] / 3600\n",
    "    user_summary['ParserCPUTime_Hours'] = user_summary['ParserCPUTime'] / 3600\n",
    "    user_summary['TotalIOInKB_GB'] = user_summary['TotalIOInKB'] / 1024**2\n",
    "    \n",
    "    print(\"\\nTop 10 Users by Total CPU Time:\")\n",
    "    print(\"=\" * 120)\n",
    "    display(user_summary.head(10)[[\n",
    "        'UserName', 'TotalCPUTime_Hours', 'AMPCPUTime_Hours', 'ParserCPUTime_Hours',\n",
    "        'QueryCount', 'TotalIOInKB_GB'\n",
    "    ]])\n",
    "    \n",
    "    # Calculate percentage of total\n",
    "    total_cpu = user_summary['TotalCPUTime'].sum()\n",
    "    top_10_cpu = user_summary.head(10)['TotalCPUTime'].sum()\n",
    "    print(f\"\\nTop 10 users consume {top_10_cpu/total_cpu*100:.1f}% of total CPU time\")\n",
    "else:\n",
    "    print(\"No data available for user ranking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03807ee9",
   "metadata": {},
   "source": [
    "## 8. Visualize Top 10 CPU Users\n",
    "\n",
    "Bar chart showing the top 10 users by CPU consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358615f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Get top 10 users\n",
    "    top_users = user_summary.head(10)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=top_users,\n",
    "        x='UserName',\n",
    "        y='TotalCPUTime_Hours',\n",
    "        palette='rocket'\n",
    "    )\n",
    "    plt.title('Top 10 Users by Total CPU Time (Hours)', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('User Name', fontsize=12)\n",
    "    plt.ylabel('Total CPU Time (Hours)', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263747b9",
   "metadata": {},
   "source": [
    "## 9. CPU Usage Per Day Over Period\n",
    "\n",
    "Plot total CPU usage aggregated by day over the entire time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Ensure TotalCPUTime is calculated\n",
    "    if 'TotalCPUTime' not in df.columns:\n",
    "        df['TotalCPUTime'] = df['AMPCPUTime'] + df['ParserCPUTime']\n",
    "    \n",
    "    # Aggregate by LogDate\n",
    "    daily_cpu = df.groupby('LogDate')['TotalCPUTime'].sum().reset_index()\n",
    "    daily_cpu['TotalCPUTime_Hours'] = daily_cpu['TotalCPUTime'] / 3600\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.plot(daily_cpu['LogDate'], daily_cpu['TotalCPUTime_Hours'], \n",
    "             marker='o', linewidth=2, markersize=4, color='#2E86AB')\n",
    "    plt.title('Total CPU Usage Per Day Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Log Date', fontsize=12)\n",
    "    plt.ylabel('Total CPU Time (Hours)', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nDaily CPU Statistics:\")\n",
    "    print(f\"  Average CPU per day: {daily_cpu['TotalCPUTime_Hours'].mean():,.2f} hours\")\n",
    "    print(f\"  Peak CPU day:        {daily_cpu['TotalCPUTime_Hours'].max():,.2f} hours on {daily_cpu.loc[daily_cpu['TotalCPUTime_Hours'].idxmax(), 'LogDate']}\")\n",
    "    print(f\"  Minimum CPU day:     {daily_cpu['TotalCPUTime_Hours'].min():,.2f} hours on {daily_cpu.loc[daily_cpu['TotalCPUTime_Hours'].idxmin(), 'LogDate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678f99b",
   "metadata": {},
   "source": [
    "## 10. CPU Usage Distribution by Top Users\n",
    "\n",
    "Pie chart showing CPU distribution among top users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Get top 10 users and aggregate others\n",
    "    top_n = 10\n",
    "    top_users = user_summary.head(top_n)\n",
    "    other_cpu = user_summary['TotalCPUTime'][top_n:].sum()\n",
    "    \n",
    "    # Create pie data\n",
    "    pie_data = top_users[['UserName', 'TotalCPUTime']].copy()\n",
    "    pie_data = pd.concat([\n",
    "        pie_data,\n",
    "        pd.DataFrame({'UserName': ['Others'], 'TotalCPUTime': [other_cpu]})\n",
    "    ])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(\n",
    "        pie_data['TotalCPUTime'],\n",
    "        labels=pie_data['UserName'],\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=140\n",
    "    )\n",
    "    plt.title('CPU Usage Distribution by User', fontsize=14, fontweight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de861dec",
   "metadata": {},
   "source": [
    "## 11. Top Users CPU Trends Over Time\n",
    "\n",
    "Line plot showing CPU usage trends for top 6 users over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fb1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Get top 6 users by total CPU\n",
    "    top_6_users = user_summary.head(6)['UserName'].tolist()\n",
    "    \n",
    "    # Filter data for top users\n",
    "    df_top = df[df['UserName'].isin(top_6_users)].copy()\n",
    "    \n",
    "    if 'TotalCPUTime' not in df_top.columns:\n",
    "        df_top['TotalCPUTime'] = df_top['AMPCPUTime'] + df_top['ParserCPUTime']\n",
    "    \n",
    "    # Aggregate by user and date\n",
    "    user_daily = df_top.groupby(['LogDate', 'UserName'])['TotalCPUTime'].sum().reset_index()\n",
    "    user_daily['TotalCPUTime_Hours'] = user_daily['TotalCPUTime'] / 3600\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for user in top_6_users:\n",
    "        user_data = user_daily[user_daily['UserName'] == user]\n",
    "        plt.plot(user_data['LogDate'], user_data['TotalCPUTime_Hours'], \n",
    "                marker='o', linewidth=2, label=user, alpha=0.7)\n",
    "    \n",
    "    plt.title('CPU Usage Trends for Top 6 Users Over Time', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Log Date', fontsize=12)\n",
    "    plt.ylabel('Total CPU Time (Hours)', fontsize=12)\n",
    "    plt.legend(loc='best', fontsize=10)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for trend analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96392364",
   "metadata": {},
   "source": [
    "## 12. Query Count Analysis\n",
    "\n",
    "Analyze query counts by user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b568ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Top users by query count\n",
    "    query_summary = df.groupby('UserName')['QueryCount'].sum().reset_index()\n",
    "    query_summary = query_summary.sort_values('QueryCount', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 20 Users by Query Count:\")\n",
    "    print(\"=\" * 80)\n",
    "    display(query_summary.head(20))\n",
    "    \n",
    "    # Plot top 10 by query count\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=query_summary.head(10),\n",
    "        x='UserName',\n",
    "        y='QueryCount',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('Top 10 Users by Query Count', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('User Name', fontsize=12)\n",
    "    plt.ylabel('Query Count', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for query analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3dde30",
   "metadata": {},
   "source": [
    "## 13. Export Results to CSV (Optional)\n",
    "\n",
    "Save the results to CSV files for further analysis or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path('output')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Save full data\n",
    "    filename = f\"dbql_summary_{start_date}_{end_date}.csv\"\n",
    "    output_path = output_dir / filename\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Full data exported to: {output_path}\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  File size: {output_path.stat().st_size / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Save user summary\n",
    "    user_summary_path = output_dir / f\"dbql_user_summary_{start_date}_{end_date}.csv\"\n",
    "    user_summary.to_csv(user_summary_path, index=False)\n",
    "    print(f\"\\n✓ User summary exported to: {user_summary_path}\")\n",
    "    \n",
    "    # Save daily CPU data\n",
    "    daily_cpu_path = output_dir / f\"dbql_daily_cpu_{start_date}_{end_date}.csv\"\n",
    "    daily_cpu.to_csv(daily_cpu_path, index=False)\n",
    "    print(f\"✓ Daily CPU data exported to: {daily_cpu_path}\")\n",
    "else:\n",
    "    print(\"No data to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a8c4c",
   "metadata": {},
   "source": [
    "## 14. Close Connections\n",
    "\n",
    "Properly clean up database connections when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f02ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'report' in locals():\n",
    "        report.close()\n",
    "        print(\"✓ All database connections closed successfully\")\n",
    "    else:\n",
    "        print(\"No report instance to close\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error closing connections: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
