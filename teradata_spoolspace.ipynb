{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8a93193",
   "metadata": {},
   "source": [
    "# Teradata SpoolSpace History Report\n",
    "\n",
    "This notebook demonstrates how to retrieve spool space usage history from Teradata PDCR data using the `PDCRInfoReport` class.\n",
    "\n",
    "**Report Parameters:**\n",
    "- Database filter: `DWP01%` (all databases starting with DWP01)\n",
    "- Time range: Last 3 years\n",
    "- Data source: `PDCRINFO.SpoolSpace_Hst`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff0365",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries for PDCR reporting and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a89b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import the reporting module\n",
    "from src.reports import PDCRInfoReport\n",
    "from src.connection import TeradataConnectionError\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e1eba",
   "metadata": {},
   "source": [
    "## 2. Configure Date Range\n",
    "\n",
    "Calculate the date range for the last 3 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cf0c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate last 3 years date range\n",
    "end_date = date.today() - timedelta(days=1)  # Yesterday\n",
    "start_date = end_date - timedelta(days=3*365)   # 3 years ago\n",
    "\n",
    "# Database filter pattern\n",
    "database_pattern = \"DWP01%\"\n",
    "\n",
    "print(f\"Date Range:\")\n",
    "print(f\"  Start Date: {start_date}\")\n",
    "print(f\"  End Date:   {end_date}\")\n",
    "print(f\"  Database Pattern: {database_pattern}\")\n",
    "print(f\"  Days: {(end_date - start_date).days + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80286a8",
   "metadata": {},
   "source": [
    "## 3. Initialize PDCR Report Generator\n",
    "\n",
    "Create an instance of the `PDCRInfoReport` class to access PDCR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39067711",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Initialize the report generator\n",
    "    report = PDCRInfoReport()\n",
    "    print(\"✓ PDCRInfoReport initialized successfully\")\n",
    "    \n",
    "    # List available environments\n",
    "    environments = report.conn_mgr.list_environments()\n",
    "    print(f\"✓ Available environments: {environments}\")\n",
    "    \n",
    "except TeradataConnectionError as e:\n",
    "    print(f\"✗ Connection Error: {e}\")\n",
    "    print(\"\\nPlease ensure:\")\n",
    "    print(\"1. td_env.yaml file exists in the project root\")\n",
    "    print(\"2. Copy td_env.yaml.template to td_env.yaml\")\n",
    "    print(\"3. Update credentials for your test/prod environments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43440053",
   "metadata": {},
   "source": [
    "## 4. Retrieve SpoolSpace History Data\n",
    "\n",
    "Query `PDCRINFO.SpoolSpace_Hst` for all databases starting with `DWP01%` over the last 3 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01a42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Retrieve spoolspace history\n",
    "    df = report.get_spoolspace_history(\n",
    "        env_name='test',  # Change to 'prod' for production data\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        database_name=database_pattern\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Retrieved {len(df):,} rows from PDCRINFO.SpoolSpace_Hst\")\n",
    "    print(f\"\\nDataFrame Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error retrieving spoolspace data: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceebf723",
   "metadata": {},
   "source": [
    "## 5. Display Sample Data\n",
    "\n",
    "Preview the first few rows to understand the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"First 10 rows:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\nColumn Data Types:\")\n",
    "    print(df.dtypes)\n",
    "else:\n",
    "    print(\"No data available to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7971142",
   "metadata": {},
   "source": [
    "## 6. Data Summary Statistics\n",
    "\n",
    "Analyze the spoolspace usage across all retrieved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9796dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SPOOLSPACE SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Date range\n",
    "    print(f\"\\nDate Range:\")\n",
    "    print(f\"  First Log Date: {df['LogDate'].min()}\")\n",
    "    print(f\"  Last Log Date:  {df['LogDate'].max()}\")\n",
    "    print(f\"  Unique Dates:   {df['LogDate'].nunique()}\")\n",
    "    \n",
    "    # Database coverage\n",
    "    print(f\"\\nDatabase Coverage:\")\n",
    "    print(f\"  Unique Databases: {df['DatabaseName'].nunique()}\")\n",
    "    print(f\"  Unique Accounts:  {df['AccountName'].nunique()}\")\n",
    "    \n",
    "    # Space usage statistics (in bytes, convert to GB)\n",
    "    print(f\"\\nCurrent Spool Usage (GB):\")\n",
    "    print(f\"  Total:   {df['CURRENTSPOOL'].sum() / 1024**3:,.2f}\")\n",
    "    print(f\"  Mean:    {df['CURRENTSPOOL'].mean() / 1024**3:,.2f}\")\n",
    "    print(f\"  Median:  {df['CURRENTSPOOL'].median() / 1024**3:,.2f}\")\n",
    "    print(f\"  Max:     {df['CURRENTSPOOL'].max() / 1024**3:,.2f}\")\n",
    "    \n",
    "    print(f\"\\nPeak Spool Usage (GB):\")\n",
    "    print(f\"  Total:   {df['PEAKSPOOL'].sum() / 1024**3:,.2f}\")\n",
    "    print(f\"  Mean:    {df['PEAKSPOOL'].mean() / 1024**3:,.2f}\")\n",
    "    print(f\"  Median:  {df['PEAKSPOOL'].median() / 1024**3:,.2f}\")\n",
    "    print(f\"  Max:     {df['PEAKSPOOL'].max() / 1024**3:,.2f}\")\n",
    "    \n",
    "    print(f\"\\nMax Spool Usage (GB):\")\n",
    "    print(f\"  Total:   {df['MAXSPOOL'].sum() / 1024**3:,.2f}\")\n",
    "    print(f\"  Mean:    {df['MAXSPOOL'].mean() / 1024**3:,.2f}\")\n",
    "    print(f\"  Median:  {df['MAXSPOOL'].median() / 1024**3:,.2f}\")\n",
    "    print(f\"  Max:     {df['MAXSPOOL'].max() / 1024**3:,.2f}\")\n",
    "    \n",
    "    # Skew statistics\n",
    "    print(f\"\\nSkew Statistics:\")\n",
    "    print(f\"  Avg Current Skew: {df['CURRENTSPOOLSKEW'].mean():.2f}%\")\n",
    "    print(f\"  Max Current Skew: {df['CURRENTSPOOLSKEW'].max():.2f}%\")\n",
    "else:\n",
    "    print(\"No data available for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b33efb",
   "metadata": {},
   "source": [
    "## 7. Top Databases by Current Spool Usage\n",
    "\n",
    "Identify the databases with highest current spool space usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e6498",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Get the most recent data for each database\n",
    "    latest_data = df.loc[df.groupby('DatabaseName')['LogDate'].idxmax()]\n",
    "    \n",
    "    # Sort by current spool usage\n",
    "    top_dbs = latest_data.nlargest(20, 'CURRENTSPOOL')[[\n",
    "        'DatabaseName', 'AccountName', \n",
    "        'CURRENTSPOOL', 'PEAKSPOOL', 'MAXSPOOL', 'CURRENTSPOOLSKEW'\n",
    "    ]].copy()\n",
    "    \n",
    "    # Convert to GB for readability\n",
    "    top_dbs['CURRENTSPOOL_GB'] = top_dbs['CURRENTSPOOL'] / 1024**3\n",
    "    top_dbs['PEAKSPOOL_GB'] = top_dbs['PEAKSPOOL'] / 1024**3\n",
    "    top_dbs['MAXSPOOL_GB'] = top_dbs['MAXSPOOL'] / 1024**3\n",
    "    \n",
    "    print(\"\\nTop 20 Databases by Current Spool Space Usage:\")\n",
    "    print(\"=\" * 120)\n",
    "    display(top_dbs[[\n",
    "        'DatabaseName', 'CURRENTSPOOL_GB', 'PEAKSPOOL_GB', 'MAXSPOOL_GB',\n",
    "        'CURRENTSPOOLSKEW'\n",
    "    ]].sort_values('CURRENTSPOOL_GB', ascending=False))\n",
    "else:\n",
    "    print(\"No data available for database ranking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96392364",
   "metadata": {},
   "source": [
    "## 8. Database-Level Aggregation\n",
    "\n",
    "Get summary statistics for each database showing spool usage patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b568ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Get most recent data\n",
    "    latest_data = df.loc[df.groupby('DatabaseName')['LogDate'].idxmax()]\n",
    "    \n",
    "    # Aggregate by database\n",
    "    db_summary = latest_data.groupby('DatabaseName').agg({\n",
    "        'CURRENTSPOOL': 'first',\n",
    "        'PEAKSPOOL': 'first',\n",
    "        'MAXSPOOL': 'first',\n",
    "        'CURRENTSPOOLSKEW': 'first'\n",
    "    }).round(2)\n",
    "    \n",
    "    # Convert to GB\n",
    "    db_summary['CURRENTSPOOL_GB'] = (db_summary['CURRENTSPOOL'] / 1024**3).round(2)\n",
    "    db_summary['PEAKSPOOL_GB'] = (db_summary['PEAKSPOOL'] / 1024**3).round(2)\n",
    "    db_summary['MAXSPOOL_GB'] = (db_summary['MAXSPOOL'] / 1024**3).round(2)\n",
    "    \n",
    "    # Sort by current usage\n",
    "    db_summary = db_summary.sort_values('CURRENTSPOOL_GB', ascending=False)\n",
    "    \n",
    "    print(\"\\nDatabase-Level Spool Space Usage Summary (Latest):\")\n",
    "    print(\"=\" * 100)\n",
    "    display(db_summary[['CURRENTSPOOL_GB', 'PEAKSPOOL_GB', 'MAXSPOOL_GB', 'CURRENTSPOOLSKEW']])\n",
    "    \n",
    "    print(f\"\\nTotal Spool Space Across All DWP01% Databases: {db_summary['CURRENTSPOOL_GB'].sum():,.2f} GB\")\n",
    "else:\n",
    "    print(\"No data available for database aggregation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03807ee9",
   "metadata": {},
   "source": [
    "## 9. Visualize Database Spool Usage\n",
    "\n",
    "Visualize the top databases by current spool space usage using a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358615f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    # Get most recent data\n",
    "    latest_data = df.loc[df.groupby('DatabaseName')['LogDate'].idxmax()]\n",
    "\n",
    "    # Get top 10 databases\n",
    "    top_dbs = latest_data.nlargest(10, 'CURRENTSPOOL')[['DatabaseName', 'CURRENTSPOOL']].copy()\n",
    "    top_dbs['CURRENTSPOOL_GB'] = top_dbs['CURRENTSPOOL'] / 1024**3\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(\n",
    "        data=top_dbs,\n",
    "        x='DatabaseName',\n",
    "        y='CURRENTSPOOL_GB',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.title('Top 10 Databases by Current Spool Space Usage (GB)')\n",
    "    plt.xlabel('Database Name')\n",
    "    plt.ylabel('Current Spool Space (GB)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263747b9",
   "metadata": {},
   "source": [
    "## 10. Spool Usage Trends Over Time\n",
    "\n",
    "Plot total spool usage for all databases over the 3-year period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total spool usage over time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    df_databases_over_time = df.groupby(['LogDate'])['CURRENTSPOOL'].sum().reset_index()\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(df_databases_over_time['LogDate'], df_databases_over_time['CURRENTSPOOL'] / 1024**3, marker='o', linewidth=2)\n",
    "    plt.title('Total Current Spool Space Usage Over 3 Years')\n",
    "    plt.xlabel('Log Date')\n",
    "    plt.ylabel('Total Current Spool Space (GB)')\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678f99b",
   "metadata": {},
   "source": [
    "## 11. Database Spool Usage Distribution\n",
    "\n",
    "Pie chart showing spool distribution among top databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ddce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as pie chart per database usage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    df_latest = df.loc[df.groupby('DatabaseName')['LogDate'].idxmax()]\n",
    "    df_db_usage = df_latest.groupby('DatabaseName')['CURRENTSPOOL'].sum().reset_index()\n",
    "    df_db_usage = df_db_usage.sort_values('CURRENTSPOOL', ascending=False)\n",
    "    \n",
    "    top_n = 5\n",
    "    df_top = df_db_usage.head(top_n)\n",
    "    df_other = pd.DataFrame({\n",
    "        'DatabaseName': ['Other'],\n",
    "        'CURRENTSPOOL': [df_db_usage['CURRENTSPOOL'][top_n:].sum()]\n",
    "    })\n",
    "    df_pie = pd.concat([df_top, df_other])\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.pie(\n",
    "        df_pie['CURRENTSPOOL'],\n",
    "        labels=df_pie['DatabaseName'],\n",
    "        autopct='%1.1f%%',\n",
    "        startangle=140\n",
    "    )\n",
    "    plt.title('Current Spool Space Usage by Database (Latest)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de861dec",
   "metadata": {},
   "source": [
    "## 12. Top Database Spool Analysis\n",
    "\n",
    "Analyze spool usage trends for the top 6 databases over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fb1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the spool usage of the top 6 databases over time in subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    df_latest = df.loc[df.groupby('DatabaseName')['LogDate'].idxmax()]\n",
    "    top_dbs = df_latest.nlargest(6, 'CURRENTSPOOL')['DatabaseName'].tolist()\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, db_name in enumerate(top_dbs):\n",
    "        ax = axes[i]\n",
    "        df_db = df[df['DatabaseName'] == db_name].sort_values('LogDate').reset_index(drop=True)\n",
    "        \n",
    "        # Plot the data\n",
    "        ax.plot(df_db.index, df_db['CURRENTSPOOL'] / 1024**3, marker='o', label='Current Spool', linewidth=2)\n",
    "        ax.plot(df_db.index, df_db['PEAKSPOOL'] / 1024**3, marker='s', label='Peak Spool', linewidth=2, alpha=0.7)\n",
    "        \n",
    "        # Add a regression line for trend\n",
    "        if len(df_db) > 1:\n",
    "            z = np.polyfit(df_db.index, df_db['CURRENTSPOOL'] / 1024**3, 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax.plot(df_db.index, p(df_db.index), \"r--\", alpha=0.7, label='Trend', linewidth=2)\n",
    "        \n",
    "        # Set x-axis labels to show dates\n",
    "        ax.set_xticks(df_db.index[::max(1, len(df_db)//5)])\n",
    "        ax.set_xticklabels([str(d) for d in df_db.loc[df_db.index[::max(1, len(df_db)//5)], 'LogDate']], rotation=45)\n",
    "        \n",
    "        ax.set_title(f'{db_name} - Spool Usage Over Time')\n",
    "        ax.set_xlabel('Log Date')\n",
    "        ax.set_ylabel('Spool Space (GB)')\n",
    "        ax.grid()\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data available for spool analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3dde30",
   "metadata": {},
   "source": [
    "## 13. Export Results to CSV (Optional)\n",
    "\n",
    "Save the results to CSV files for further analysis or reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path('output')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Generate filename with date range\n",
    "    filename = f\"spoolspace_dwp01_{start_date}_{end_date}.csv\"\n",
    "    output_path = output_dir / filename\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✓ Data exported to: {output_path}\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  File size: {output_path.stat().st_size / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    print(\"No data to export.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215a8c4c",
   "metadata": {},
   "source": [
    "## 14. Close Connections\n",
    "\n",
    "Properly clean up database connections when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f02ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if 'report' in locals():\n",
    "        report.close()\n",
    "        print(\"✓ All database connections closed successfully\")\n",
    "    else:\n",
    "        print(\"No report instance to close\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error closing connections: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
